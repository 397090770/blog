<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Madhukar&#39;s Blog</title>
    <description>Thoughts on technology, life and everything else.</description>
    <link>http://blog.madhukaraphatak.com/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Akka HTTP testing</title>
        <description>&lt;p&gt;Akka-Http is a akka based http library for building RESTful services in scala. In this series of posts, I will be talking about using akka-http to build REST services. This is the third post in the series. You can access all the posts in this series &lt;a href=&quot;/categories/akka-http/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this post, we are going to discuss testing REST API’s in akka-http.&lt;/p&gt;

&lt;p&gt;TL;TR You can access complete project on &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;testing-in-akka-http&quot;&gt;Testing in Akka HTTP&lt;/h2&gt;

&lt;p&gt;Akka HTTP puts a lot of focus on testability of code. It has a dedicated module &lt;em&gt;akka-http-testkit&lt;/em&gt; for testing rest api’s. When you use this testkit you are not need to run external web server or application server to test your rest API’s. It will do all needed the stubbing and mocking for you which greatly simplifies the testing process.&lt;/p&gt;

&lt;p&gt;In this post, first we are going to discuss how to structure our code which can be easily testable with akka testkit. Once we have structured code, then we will discuss how to write unit test cases which tests the behavior of the rest API.&lt;/p&gt;

&lt;h2 id=&quot;adding-dependency&quot;&gt;Adding dependency&lt;/h2&gt;

&lt;p&gt;You need to add akka-http-testkit library to test your rest services.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;com.typesafe.akka&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;akka-http-testkit-experimental&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;1.0&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&quot;code-structure&quot;&gt;Code structure&lt;/h2&gt;

&lt;p&gt;Before we can do any unit testing, structuring our code in a way which can allow us to unit test is very important. The below gives one of the way to structure your REST API’s. Please note that it’s one of the many structuring schema. You can follow any other ones which gives you same effect.&lt;/p&gt;

&lt;p&gt;Normally we divide our REST API to two following pieces&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;RestService - Defines the route for the rest service.&lt;/li&gt;
  &lt;li&gt;Rest server - Defines and creates the environment need to run the rest service.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This kind of way separating concerns of the API allows us to decouple the environment in which the rest service actually runs. In testing, it runs in an emulated server and in production it may runs inside an application server or it’s own server.&lt;/p&gt;

&lt;p&gt;The following sections discusses a simple API which we use to a simple customer. We have already discussed about the details of the API in &lt;a href=&quot;/json-in-akka-http&quot;&gt;previous&lt;/a&gt; post.&lt;/p&gt;

&lt;h3 id=&quot;rest-service&quot;&gt;Rest service&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RestService&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ActorSystem&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;materializer&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ActorMaterializer&lt;/span&gt;

   &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConcurrentLinkedDeque&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Customer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]()&lt;/span&gt;

   &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ServiceJsonProtoocol._&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;route&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;customer&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;post&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;entity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Customer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;got customer with name ${customer.name}&amp;quot;&lt;/span&gt;
               &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asScala&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The above code defines a trait called &lt;em&gt;RestService&lt;/em&gt; . Normally a service is a trait because it has to be mixed with some class/object to give the environment. The environment expected by the service includes&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;system - Actor System on which this service runs&lt;/li&gt;
  &lt;li&gt;materializer - Flow materializer as discussed in &lt;a href=&quot;/akka-http-helloworld&quot;&gt;earlier&lt;/a&gt; blog posts.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These values are implicits. This means we inject these externally when we instantiate this service. This is one of the way to dependency injection in scala.&lt;/p&gt;

&lt;p&gt;You can access complete code &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples/blob/master/src/main/scala/com/madhukaraphatak/akkahttp/testable/RestService.scala&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Once we have rest service ready, now we can define a REST server which serves this service.&lt;/p&gt;

&lt;h3 id=&quot;rest-server&quot;&gt;REST server&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RestServer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ActorSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;materializer&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ActorMaterializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RestService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;startServer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Http&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bindAndHandle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;route&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RestServer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actorSystem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ActorSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;rest-server&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;materializer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ActorMaterializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RestServer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startServer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;localhost&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8080&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The above code creates a REST server which extends our &lt;em&gt;RestService&lt;/em&gt;. If you observe the code, we are creating and injecting both actor system and actor materializer.&lt;/p&gt;

&lt;p&gt;This way of separating service and server allows us to inject these environment from test cases as shown in below.&lt;/p&gt;

&lt;p&gt;You can access complete code &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples/blob/master/src/main/scala/com/madhukaraphatak/akkahttp/testable/RestServer.scala&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;testing-rest-api&quot;&gt;Testing Rest API&lt;/h3&gt;

&lt;h4 id=&quot;create-spec-with-scalatestroutetest&quot;&gt;1. Create Spec with ScalatestRouteTest&lt;/h4&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RestSpec&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;WordSpec&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Matchers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ScalatestRouteTest&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RestService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The above code uses scala-test for testing. In our spec, we mix &lt;em&gt;ScalatestRouteTest&lt;/em&gt; which comes from akka-http-testkit library. It provides the actor system and flow materializer for test environment. Also we extend our &lt;em&gt;RestService&lt;/em&gt; from where we get access to route.&lt;/p&gt;

&lt;h4 id=&quot;prepare-the-request&quot;&gt;2. Prepare the request&lt;/h4&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Customer API&amp;quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;should&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;quot;Posting to /customer should add the customer&amp;quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonRequest&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ByteString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;           |{&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;           |    &amp;quot;name&amp;quot;:&amp;quot;test&amp;quot;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;           |}&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stripMargin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;postRequest&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HttpRequest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;HttpMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;POST&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;uri&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/customer&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;entity&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HttpEntity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MediaTypes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;`application/json`&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonRequest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Once we prepare the spec, we prepare the POST request. The above code shows how to create HTTP post request, using HttpRequest API akka-http models.&lt;/p&gt;

&lt;h4 id=&quot;send-request&quot;&gt;3. Send request&lt;/h4&gt;

&lt;p&gt;Once we have the request, we can send the request using ~&amp;gt; operator as below code.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;n&quot;&gt;postRequest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;route&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isSuccess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shouldEqual&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Once we send request, we can test results using many check methods. In our code, we are using status to check is our request returned 200 response. You can not only check for status, you can also test different pieces like response headers, response entity etc.&lt;/p&gt;

&lt;p&gt;You can access complete code &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples/blob/master/src/test/scala/com/madhukaraphatak/akkahttp/testable/RestSpec.scala&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now you have a rest service which can be easily unit tested.&lt;/p&gt;
</description>
        <pubDate>Fri, 20 Nov 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/akka-http-testing</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/akka-http-testing</guid>
      </item>
    
      <item>
        <title>JSON in Akka HTTP</title>
        <description>&lt;p&gt;Akka-Http is a akka based http library for building RESTful services in scala. In this series of posts, I will be talking about using akka-http to build REST services. This is the second post in the series. You can access all the posts in this series &lt;a href=&quot;/categories/akka-http/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this post, we are going to discuss how to use json with akka-http for communicating request and responses&lt;/p&gt;

&lt;p&gt;TL;TR You can access complete project on &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;adding-dependency&quot;&gt;Adding dependency&lt;/h2&gt;

&lt;p&gt;Akka HTTP uses the akka-http-spray-json library for parsing json request and responses. So add the following dependency to your project.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;com.typesafe.akka&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;akka-http-spray-json-experimental&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;1.0&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&quot;rest-api-with-json&quot;&gt;REST API with JSON&lt;/h2&gt;

&lt;p&gt;In this example, we are going to create an API which can add/list customers. The following are the steps to add the API.&lt;/p&gt;

&lt;h3 id=&quot;define-customer-model&quot;&gt;1. Define customer model&lt;/h3&gt;

&lt;p&gt;Akka HTTP uses case classes to define the models. So we define a simple customer model which has only name.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Customer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;create-writerreader-for-the-model&quot;&gt;2. Create Writer/Reader for the model&lt;/h3&gt;

&lt;p&gt;In spary-json, we have to define the write/reader for a given model in order to be used in the request/response. Most of the time it is very simple as defining the implicit as below.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ServiceJsonProtoocol&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DefaultJsonProtocol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customerProtocol&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonFormat1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Customer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above code snippet, we are creating a service protocol which extends the default protocol. Inside this protocol, we can define all the models. In above code, the number ‘1’ in jsonFormat1 signifies there is only one field in case class.&lt;/p&gt;

&lt;h3 id=&quot;defining-the-route&quot;&gt;3. Defining the route&lt;/h3&gt;

&lt;p&gt;Once we have the model and parser implicits, we can define a route which has post for adding a customer and get to get all the added customers.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;route&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;customer&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;post&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;entity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Customer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;got customer with name ${customer.name}&amp;quot;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asScala&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In above example, an entity is parsed in post request using entity(as).
Once we have the customer, we are adding it to a concurrent queue.&lt;/p&gt;

&lt;p&gt;In the get method, we are taking all the values in the list and converting to a JSArray.&lt;/p&gt;

&lt;p&gt;You can access complete code &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples/blob/master/src/main/scala/com/madhukaraphatak/akkahttp/AkkaJsonParsing.scala&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now you have a working REST api in akka-http which can handle json data.&lt;/p&gt;
</description>
        <pubDate>Fri, 13 Nov 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/json-in-akka-http</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/json-in-akka-http</guid>
      </item>
    
      <item>
        <title>Akka HTTP Hello world</title>
        <description>&lt;p&gt;Akka HTTP is a akka based http library for building RESTful services in Scala.
It’s is based on new Akka reactive streams library.&lt;/p&gt;

&lt;p&gt;In this series of posts, I will be talking about how to build REST services using akka-http library.&lt;/p&gt;

&lt;p&gt;This is the first post in the series, where I will be talking about setting up the project and running a hello world program.&lt;/p&gt;

&lt;p&gt;TL;TR You can access complete code on &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;adding-dependency&quot;&gt;Adding dependency&lt;/h2&gt;

&lt;p&gt;To start using akka-http, you should add the following dependency to project. I am using sbt for build management. You can also use other build tools like maven.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;com.typesafe.akka&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;akka-http-experimental&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;1.0&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Though the artifact name says it’s experimental many companies are using it in the production.&lt;/p&gt;

&lt;p&gt;You can access complete build.sbt &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples/blob/master/build.sbt&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;helloworld-application&quot;&gt;HelloWorld application&lt;/h2&gt;

&lt;p&gt;The following are the steps to be followed to create a hello world application.&lt;/p&gt;

&lt;h3 id=&quot;create-actor-system&quot;&gt;1. Create Actor System&lt;/h3&gt;

&lt;p&gt;Akka HTTP uses akka actors for handling concurrent requests. So in the first line we have to create akka actor system.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actorSystem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ActorSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;system&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;create-actorflowmaterilizer&quot;&gt;2. Create ActorFlowMaterilizer&lt;/h3&gt;

&lt;p&gt;Akka HTTP uses akka reactive streams for stream processing on TPC. So in a reactive system,we need to specify flow materializer which specifies the how requests/repose flow get processed. In akka-http, actors will be used for handling request and response flows. So we use &lt;em&gt;ActorMaterializer&lt;/em&gt; here.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actorMaterializer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ActorMaterializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Please make sure both of the variables are implicits. Otherwise you may get strange cryptic compilation errors.&lt;/p&gt;

&lt;h3 id=&quot;defining-the-route&quot;&gt;3. Defining the route&lt;/h3&gt;

&lt;p&gt;Route specifies the URI endpoints REST server exposing. It is combination of multiple paths.&lt;/p&gt;

&lt;p&gt;A simple path has the following three parts&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Directive/URI&lt;/li&gt;
  &lt;li&gt;HTTP Method&lt;/li&gt;
  &lt;li&gt;Response&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;route&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pathSingleSlash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&amp;quot;Hello world&amp;quot;&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In above example, we are creating a route with following properties&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;/ is the directive&lt;/li&gt;
  &lt;li&gt;get is HTTP Method&lt;/li&gt;
  &lt;li&gt;Returns “hello world” as the response&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bind&quot;&gt;4. Bind&lt;/h3&gt;

&lt;p&gt;Once we have all pieces in place, we need to create a server and bind to this route, address and port.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;nc&quot;&gt;Http&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bindAndHandle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;route&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;localhost&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8080&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This creates and runs a simple http server at &lt;a href=&quot;http://localhost:8080&quot;&gt;http://localhost:8080&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can access complete code for this server &lt;a href=&quot;https://github.com/phatak-dev/akka-http-examples/blob/master/src/main/scala/com/madhukaraphatak/akkahttp/AkkaHttpHelloWorld.scala&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now we have a working simple http server using akka-http library.&lt;/p&gt;
</description>
        <pubDate>Fri, 13 Nov 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/akka-http-helloworld</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/akka-http-helloworld</guid>
      </item>
    
      <item>
        <title>Introduction to Machine learning with Spark</title>
        <description>&lt;p&gt;The below video is a recording of my talk on Introduction to machine learning with Spark in recent spark meet up. It’s a talk about how machine learning is implemented using Spark RDD concepts and how to use built in libraries like MLLib.&lt;/p&gt;

&lt;p&gt;Find the slides on &lt;a href=&quot;http://www.slideshare.net/datamantra/introduction-to-machine-learning-with-spark&quot;&gt;slideshare&lt;/a&gt; and code on &lt;a href=&quot;https://github.com/phatak-dev/introduction_to_ml_with_spark&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;video-container&quot;&gt; &lt;iframe src=&quot;https://www.youtube.com/embed/gRg2m_95c-0&quot; frameborder=&quot;0&quot; width=&quot;560&quot; height=&quot;315&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;

&lt;div class=&quot;video-container&quot;&gt; &lt;iframe src=&quot;https://www.youtube.com/embed/pehFa-biOyE&quot; frameborder=&quot;0&quot; width=&quot;560&quot; height=&quot;315&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;
</description>
        <pubDate>Sat, 19 Sep 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/machine-learning-with-spark</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/machine-learning-with-spark</guid>
      </item>
    
      <item>
        <title>Improving Mobile payments with Real time Spark</title>
        <description>&lt;p&gt;The below video is a recording of my talk on &lt;em&gt;Improving mobile payments with real time spark&lt;/em&gt; in recent spark meetup. It’s a talk about real world spark streaming implementation for improving mobile payments experience.&lt;/p&gt;

&lt;p&gt;Find the slides on &lt;a href=&quot;http://www.slideshare.net/datamantra/improving-mobile-payments-with-real-time-spark&quot;&gt;slideshare&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;video-container&quot;&gt; &lt;iframe src=&quot;https://www.youtube.com/embed/Q7O_AOTZ2C8&quot; frameborder=&quot;0&quot; width=&quot;560&quot; height=&quot;315&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;
</description>
        <pubDate>Wed, 05 Aug 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/improving-mobile-payments-with-real-time-spark</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/improving-mobile-payments-with-real-time-spark</guid>
      </item>
    
      <item>
        <title>Anatomy of Data Frame API : Deep dive into Spark SQL Data Frame API</title>
        <description>&lt;p&gt;The below video is a screen cast  of my talk on &lt;em&gt;Anatomy of Data Frame API : Deep dive into Spark SQL Data Frame API&lt;/em&gt; in recent spark meetup. In this talk, we will discuss about internals of dataframe.&lt;/p&gt;

&lt;p&gt;Find the slides on &lt;a href=&quot;http://www.slideshare.net/datamantra/anatomy-of-data-frame-api&quot;&gt;slideshare&lt;/a&gt; and code on &lt;a href=&quot;https://github.com/phatak-dev/anatomy_of_spark_dataframe_api&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;video-container&quot;&gt; &lt;iframe src=&quot;https://www.youtube.com/embed/iKOGBr-kOks&quot; frameborder=&quot;0&quot; width=&quot;560&quot; height=&quot;315&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;
</description>
        <pubDate>Wed, 05 Aug 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/anatomy-of-spark-dataframe-api</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/anatomy-of-spark-dataframe-api</guid>
      </item>
    
      <item>
        <title>Anatomy of Data Source API : Deep dive into Spark SQL Data Source API</title>
        <description>&lt;p&gt;The below video is a screen cast  of my talk on &lt;em&gt;Anatomy of Data Source API : Deep dive into Spark SQL Data Source API&lt;/em&gt; in recent spark meetup. In this talk, I discuss about how to create a data source from scratch using Spark SQL data source API’s.&lt;/p&gt;

&lt;p&gt;Find the slides on &lt;a href=&quot;http://www.slideshare.net/datamantra/anatomy-of-data-source-api&quot;&gt;slideshare&lt;/a&gt; and code on &lt;a href=&quot;https://github.com/phatak-dev/anatomy_of_spark_datasource_api&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;video-container&quot;&gt; &lt;iframe src=&quot;https://www.youtube.com/embed/ckX6fT3kYG0&quot; frameborder=&quot;0&quot; width=&quot;560&quot; height=&quot;315&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;
</description>
        <pubDate>Tue, 30 Jun 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/anatomy-of-spark-datasource-api</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/anatomy-of-spark-datasource-api</guid>
      </item>
    
      <item>
        <title>Structured data processing with Spark SQL - Meetup Video</title>
        <description>&lt;p&gt;The below video is a recording of my talk on &lt;em&gt;Structured data processing with Spark SQL&lt;/em&gt; in recent spark meetup. In this talk, I discuss about how you can use spark sql API’s like Data source, Data frame API’s
to analyse structured data with Spark.&lt;/p&gt;

&lt;p&gt;Find the slides on &lt;a href=&quot;http://www.slideshare.net/datamantra/introduction-to-structured-data-in-spark&quot;&gt;slideshare&lt;/a&gt; and code on &lt;a href=&quot;https://github.com/phatak-dev/structured_data_processing_spark_sql&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;video-container&quot;&gt; &lt;iframe src=&quot;https://www.youtube.com/embed/0jd3EWmKQfo&quot; frameborder=&quot;0&quot; width=&quot;560&quot; height=&quot;315&quot;&gt;&lt;/iframe&gt; &lt;/div&gt;
</description>
        <pubDate>Mon, 08 Jun 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/structured-data-processing-with-spark-sql-meetup-talk</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/structured-data-processing-with-spark-sql-meetup-talk</guid>
      </item>
    
      <item>
        <title>Analysing CSV data in Spark : Introduction to Spark Data Source API - Part 2</title>
        <description>&lt;p&gt;Data source is an API for handling structured data in Spark. It was introduced in Spark 1.2 as part of Spark SQL package.
It brings a new way of reading data apart from InputFormat API which was adopted from hadoop. In the next series of blog posts,  I will be discussing how to load and query different kind of structured data using data source API.&lt;/p&gt;

&lt;p&gt;This is the second post in the series in which we discuss how to handle csv data in spark. You can find other
blog posts of the series &lt;a href=&quot;/categories/datasource-series/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;spark-csv&quot;&gt;Spark-csv&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/databricks/spark-csv&quot;&gt;Spark-csv&lt;/a&gt; is a community library provided by Databricks to
parse and query csv data in the spark. This library adheres to the data source API both for reading and
writing csv data.&lt;/p&gt;

&lt;h3 id=&quot;csv-loading&quot;&gt;Csv Loading&lt;/h3&gt;

&lt;p&gt;In this section, we are going to look at how to load and query CSV data.
You can find sample &lt;a href=&quot;https://github.com/phatak-dev/blog/blob/master/code/DataSourceExamples/src/main/resources/sales.csv&quot;&gt;data&lt;/a&gt; and complete project on &lt;a href=&quot;https://github.com/phatak-dev/blog/tree/master/code/DataSourceExamples&quot;&gt;github&lt;/a&gt;. For detailed steps
about data source API, please refer to this &lt;a href=&quot;/introduction-to-spark-data-source-api-part-1&quot;&gt;post&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Csv loading example&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SQLContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;com.databricks.spark.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;path&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;header&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;true&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printSchema&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above code, we pass &lt;em&gt;com.databricks.spark.csv&lt;/em&gt; to load method to signify that we want to read csv data. Also in the
second parameter, we pass &lt;em&gt;“header”-&amp;gt;”true”&lt;/em&gt; to tell that, the first line of the file is a header.&lt;/p&gt;

&lt;h3 id=&quot;querying-csv-data&quot;&gt;Querying CSV Data&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;registerTempTable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;sales&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aggDF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;select sum(amountPaid) from sales&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aggDF&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collectAsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Once we load data as dataframe, querying is exactly same as any other data source. You can access complete
code on &lt;a href=&quot;https://github.com/phatak-dev/blog/blob/master/code/DataSourceExamples/src/main/scala/com/madhukaraphatak/spark/datasource/CsvDataInput.scala&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;save-as-csv&quot;&gt;Save as CSV&lt;/h3&gt;

&lt;p&gt;In the previous section, we looked at how to load and query the data in CSV. In this section, we are going to
look how to save a dataframe as CSV file. In this example, we will load data from json and then save it as csv file.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;Csv loading example&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SQLContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;org.apache.spark.sql.json&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;path&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;com.databricks.spark.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SaveMode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ErrorIfExists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;path&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;header&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;true&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first 3 lines of code loads json data. The last line saves the constructed data frame as a csv file.  The
&lt;em&gt;save&lt;/em&gt; is an universal method in data source API to save to any source. The following are the parameters passed to save method.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;source - it same as &lt;em&gt;load&lt;/em&gt; method. It says we want to save as csv.&lt;/li&gt;
  &lt;li&gt;SaveMode - allows user to signify what has to be done if the given output path already exists. You can throw error, append or
 overwrite. In our example, we will thrown an error as we don’t want to overwrite any existing file.&lt;/li&gt;
  &lt;li&gt;Options - These options are same as what we passed to &lt;em&gt;load&lt;/em&gt; method. Here we specify the output path and
specify that the first line output file has to be header.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can access complete code on &lt;a href=&quot;https://github.com/phatak-dev/blog/blob/master/code/DataSourceExamples/src/main/scala/com/madhukaraphatak/spark/datasource/CsvDataOutput.scala&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So from the above sections, it’s obvious that data source API brings a very easy to use interface to structured data. You can
load, query and change between multiple sources with few lines of code.&lt;/p&gt;
</description>
        <pubDate>Tue, 26 May 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/analysing-csv-data-in-spark</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/analysing-csv-data-in-spark</guid>
      </item>
    
      <item>
        <title>Introduction to Spark Data Source API - Part 1</title>
        <description>&lt;p&gt;Data source is an API for handling structured data in Spark. It was introduced in Spark 1.2 as part of Spark SQL package.
It brings a new way of reading data apart from InputFormat API which was adopted from hadoop. In the next series of blog posts,  I will be discussing how to load and query different kind of structured data using data source API.&lt;/p&gt;

&lt;p&gt;This is the first post in the series about how to get started and how to do json data handling.&lt;/p&gt;

&lt;h2 id=&quot;reading-data-in-spark&quot;&gt;Reading Data in Spark&lt;/h2&gt;

&lt;p&gt;InputFormat was the only way to load data till Spark 1.1. Thought it’s a great API, it is not
suited for all  data sources. Particularly structured data sources like JSON, JDBC where we need
a better integration for schema discovery and smart filtering. Data source API bring the tighter
integration with the structured sources which will improve developer productivity and also performance.&lt;/p&gt;

&lt;h2 id=&quot;built-in-sources&quot;&gt;Built in sources&lt;/h2&gt;

&lt;p&gt;The support for following sources are built into Spark-SQL.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JSON&lt;/li&gt;
  &lt;li&gt;Parquet&lt;/li&gt;
  &lt;li&gt;JDBC&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But you are not limited by that. There are many other data sources supported by community.
The following are the few&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/databricks/spark-csv&quot;&gt;CSV&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Stratio/spark-mongodb&quot;&gt;MongoDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can find more on &lt;a href=&quot;http://spark-packages.org/&quot;&gt;spark-packages&lt;/a&gt; website.&lt;/p&gt;

&lt;h2 id=&quot;json-querying&quot;&gt;Json Querying&lt;/h2&gt;

&lt;p&gt;In this section, we are going to look at load and query JSON data. JSON support is built in. The following section
gives you step by step instructions for that. You can find sample &lt;a href=&quot;https://github.com/phatak-dev/blog/blob/master/code/DataSourceExamples/src/main/resources/sales.json&quot;&gt;data&lt;/a&gt; and
complete project on &lt;a href=&quot;https://github.com/phatak-dev/blog/tree/master/code/DataSourceExamples&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;step-1--creating-sqlcontext&quot;&gt;Step 1 : Creating SQLContext&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SQLContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You need to create SQLContext in order to access any data source API.&lt;/p&gt;

&lt;h3 id=&quot;step-2--load-function-to-load-schema-from-source&quot;&gt;Step 2 : Load function to load schema from source&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;org.apache.spark.sql.json&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;path&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;load is an universal way of loading data from any data source supported by data source API. The first
parameter takes the class name of source. In this example &lt;em&gt;org.apache.spark.sql.json&lt;/em&gt; point to that
data source is JSON. Second parameter is a map options of data source. The parameter we are passing
here path of the JSON file. The return value will be a DataFrame.&lt;/p&gt;

&lt;h3 id=&quot;step-3--printing-schema&quot;&gt;Step 3 : Printing schema&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printSchema&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When you load the data, most of sources will automatically discover schema from the data. In this example,
JSON schema is interpreted from the json keys and value. So after load, we can print the schema.&lt;/p&gt;

&lt;h3 id=&quot;step-4--querying-json-using-sql&quot;&gt;Step 4 : Querying JSON using sql&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;registerTempTable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;sales&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aggDF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;select sum(amountPaid) from sales&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above code, we register our dataframe as a temp table called &lt;em&gt;sales&lt;/em&gt;. Once we have registered table,
we can run any sql query using sqlContext.&lt;/p&gt;

&lt;h3 id=&quot;step-5--print-the-result&quot;&gt;Step 5 : Print the result&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aggDF&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collectAsList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can call collect get the results.&lt;/p&gt;
</description>
        <pubDate>Mon, 25 May 2015 00:00:00 +0530</pubDate>
        <link>http://blog.madhukaraphatak.com/introduction-to-spark-data-source-api-part-1</link>
        <guid isPermaLink="true">http://blog.madhukaraphatak.com/introduction-to-spark-data-source-api-part-1</guid>
      </item>
    
  </channel>
</rss>
